{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and NetID below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Punit K. Jha\"\n",
    "NetID = \"punit2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 2: Text Classification\n",
    "=============\n",
    "\n",
    "In this problem set, you will build a system for automatically classifying song lyrics comments by era. You will:\n",
    "\n",
    "- Do some basic text processing, tokenizing your input and converting it into a bag-of-words representation\n",
    "- Build a machine learning classifier based on the generative model, using Naive Bayes\n",
    "- Evaluate your classifiers and examine what they have learned\n",
    "- Build a logistic regression classifier (discriminative model) using PyTorch\n",
    "\n",
    "Total Points: 100 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "\n",
    "In order to develop this assignment, you will need [python 3.6](https://www.python.org/downloads/) and the following libraries. Most if not all of these are part of [anaconda](https://www.continuum.io/downloads), so a good starting point would be to install that.\n",
    "\n",
    "- [jupyter](http://jupyter.readthedocs.org/en/latest/install.html)\n",
    "- numpy (This will come if you install scipy like above, but if not install separately)\n",
    "- [matplotlib](http://matplotlib.org/users/installing.html)\n",
    "- [nosetests](https://nose.readthedocs.org/en/latest/)\n",
    "- [pandas](http://pandas.pydata.org/) Dataframes\n",
    "\n",
    "Here is some help on installing packages in python: https://packaging.python.org/installing/. You can use ```pip --user``` to install locally without sudo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this assignment\n",
    "\n",
    "- This is a Jupyter notebook. You can execute cell blocks by pressing control-enter.\n",
    "- Most of your coding will be in the python source files in the directory ```gtnlplib```. Some functions in these source files will remain empty, and we will not touch them. Do not worry about that, and do not assume you are doing something wrong.\n",
    "- The directory ```tests``` contains unit tests that will be used to grade your assignment, using ```nosetests```. You should run them as you work on the assignment to see that you're on the right track. You are free to look at their source code, if that helps -- though most of the relevant code is also here in this notebook. Learn more about running unit tests at http://pythontesting.net/framework/nose/nose-introduction/\n",
    "- You may want to add more tests, but that is completely optional. \n",
    "- **To submit this assignment, rename the whole directory as your NetID. Compress the whole directory using tar or zip, and submit ```Your_NetID.tgz``` or ```Your_NetID.zip``` on Compass.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Python version\n",
      "python: 3.7.4 (default, Aug 13 2019, 20:35:49) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "print('My Python version')\n",
    "\n",
    "print('python: {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nose\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My library versions\n",
      "pandas: 0.25.1\n",
      "numpy: 1.17.2\n",
      "scipy: 1.3.1\n",
      "matplotlib: 3.1.1\n",
      "nose: 1.3.7\n",
      "torch: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "print('My library versions')\n",
    "\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('scipy: {}'.format(sp.__version__))\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('nose: {}'.format(nose.__version__))\n",
    "print('torch: {}'.format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether your libraries are the right version, run:\n",
    "\n",
    "`nosetests tests/test_environment.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 0.001s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "# use ! to run shell commands in notebook\n",
    "! nosetests tests/test_environment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing\n",
    "\n",
    "**Total: 15 points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('lyrics-train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe is a structured representation of your data. You can preview a dataframe using `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pre-1980' '1980s' 'pre-1980' ... '1980s' '2000s' '1990s']\n"
     ]
    }
   ],
   "source": [
    "df_train.head()\n",
    "# print(df_train[0:20])\n",
    "print(df_train['Era'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bags of words\n",
    "\n",
    "Your first task is to convert the text to a bag-of-words representation. For this data, a lot of the preprocessing is already done: the text is lower-cased, and punctuation is removed. You need only create a `counter` for each instance.\n",
    "\n",
    "- **Deliverable 1.1**: Complete the function `gtnlplib.preproc.bag_of_words`. (5 points)\n",
    "- **Test**: `nose tests/test_preproc.py:test_d1_1_bow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtnlplib import preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this block to update the notebook as you change the preproc library\n",
    "reload(preproc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr,x_tr = preproc.read_data('lyrics-train.csv',preprocessor=preproc.bag_of_words)\n",
    "y_dv,x_dv = preproc.read_data('lyrics-dev.csv',preprocessor=preproc.bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 67.061s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "y_te,x_te = preproc.read_data('lyrics-test-hidden.csv',preprocessor=preproc.bag_of_words)\n",
    "! nosetests tests/test_preproc.py:test_d1_1_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7ea9eadc0a3c81134d098f87cd6e44f",
     "grade": true,
     "grade_id": "cell-e14a884a66838eb7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unseen words\n",
    "\n",
    "One challenge for classification is that words will appear in the test data that do not appear in the training data. Compute the number of words that appear in `lyrics-dev.csv`, but not in `lyrics-train.csv`. To do this, implement the following deliverables:\n",
    "\n",
    "- **Deliverable 1.2**: implement `gtnlplib.preproc.compute_oov`, returning a list of words that appear in one list of bags-of-words, but not another.  (5 points)\n",
    "- **Tests**: `tests/test_preproc.py:test_d1_3a_oov`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(preproc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write fast code, you can find bottlenecks using the %%timeit cell magic. (The following line will run for about 5 mins.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 1s ± 771 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preproc.aggregate_counts(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dv = preproc.aggregate_counts(x_dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the most common items in a counter by calling `counts.most_common()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 5542), ('i', 5535), ('the', 5061), ('to', 3203), ('and', 2953)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_dv.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_tr = preproc.aggregate_counts(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2677"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preproc.compute_oov(counts_dv,counts_tr))\n",
    "# print((counts_dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30459"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preproc.compute_oov(counts_tr,counts_dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.297246280257606"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.oov_rate(counts_dv,counts_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 67.111s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_preproc.py:test_d1_1_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81af4ec0952c8a041ab623fac8ed27c8",
     "grade": true,
     "grade_id": "cell-482f1c249c42fb09",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30% of the words in the dev set do not appear in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning the vocabulary\n",
    "\n",
    "Let's prune the vocabulary to include only words that appear at least ten times in the training data.\n",
    "\n",
    "- **Deliverable 1.3:** Implement `preproc.prune_vocabulary` (5 points)\n",
    "- **Test**: `tests/test_preproc.py:test_d1_4_prune`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(preproc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_pruned, vocab = preproc.prune_vocabulary(counts_tr,x_tr,10)\n",
    "x_dv_pruned, _ = preproc.prune_vocabulary(counts_tr,x_dv,10)\n",
    "x_te_pruned, _ = preproc.prune_vocabulary(counts_tr,x_te,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4875"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 79\n",
      "187 176\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 89.185s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "i = 94\n",
    "print(len(x_dv[i]),len(x_dv_pruned[i]))\n",
    "print(sum(x_dv[i].values()),sum(x_dv_pruned[i].values()))\n",
    "! nosetests tests/test_preproc.py:test_d1_4_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "115c33ee87cd813df95bc975139fe057",
     "grade": true,
     "grade_id": "cell-66cf51b57c93d393",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear classification\n",
    "\n",
    "Now we'll show you how to implement the linear classification rule, $\\hat{y} = \\text{argmax}_y \\theta^{\\top} f(x,y)$.\n",
    "\n",
    "You will use these functions in all classifiers in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtnlplib import clf_base\n",
    "reload(clf_base)\n",
    "\n",
    "from gtnlplib import constants\n",
    "reload(constants);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature function vector $f(x,y)$ can be viewed as a dict, in which the values are counts, and the keys are tuples $(y,x_j)$, where $y$ is a label and $x_j$ is a base feature. Note that we must also include the offset feature, ```gtnlplib.constants.OFFSET```. Desired output is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = clf_base.make_feature_vector({'test':1,'case':2},'1980s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('1980s', 'test'): 1, ('1980s', 'case'): 2, ('1980s', '**OFFSET**'): 1}\n"
     ]
    }
   ],
   "source": [
    "print(fv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the entire set of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1980s', 'pre-1980', '2000s', '1990s'}\n"
     ]
    }
   ],
   "source": [
    "labels = set(y_tr) #figure out all possible labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 76.041s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_classifier.py:test_d2_1_featvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement the prediction rule, $\\hat{y} = \\text{argmax}_y \\theta^{\\top} f(x,y)$.\n",
    "\n",
    "The output should be:\n",
    "\n",
    "- A predicted label\n",
    "- The scores of all labels\n",
    "\n",
    "You can test this function using these simple hand-crafted weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gtnlplib.clf_base' from '/home/punit/Desktop/Machine_Learning/ECE_365/NLP_Lab2/punit2/NLPLab2/gtnlplib/clf_base.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "reload(clf_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight vectors must be defaultdicts\n",
    "theta_hand = defaultdict(float,\n",
    "                         {('2000s','money'):0.1,\n",
    "                          ('2000s','name'):0.2,\n",
    "                          ('1980s','tonight'):0.1,\n",
    "                          ('2000s','man'):0.1,\n",
    "                          ('1990s','fly'):0.1,\n",
    "                          ('pre-1980',constants.OFFSET):0.1\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2000s',\n",
       " {'1980s': 0.0, 'pre-1980': 0.1, '2000s': 1.3000000000000003, '1990s': 0.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_base.predict(x_tr_pruned[0],theta_hand,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how good these weights are, by evaluating on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtnlplib import evaluation\n",
    "reload(evaluation);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3422222222222222\n"
     ]
    }
   ],
   "source": [
    "# this applies your predict function to all the instances in ```x_dv```\n",
    "y_hat = clf_base.predict_all(x_dv_pruned,theta_hand,labels)\n",
    "print(evaluation.acc(y_hat,y_dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 82.032s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_classifier.py:test_d2_2_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Naive Bayes\n",
    "\n",
    "You'll now implement a Naive Bayes classifier in this section.\n",
    "\n",
    "**Total: 40 points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtnlplib import naive_bayes\n",
    "reload(naive_bayes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deliverable 3.1**: (warmup) implement ```get_corpus_counts``` in ```naive_bayes.py```. (5 points)\n",
    "- **Test**: `tests/test_classifier.py:test_d3_1_corpus_counts`\n",
    "\n",
    "This function should compute the word counts for a given label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "14\n",
      "0.0\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 75.156s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "eighties_counts = naive_bayes.get_corpus_counts(x_tr_pruned,y_tr,\"1980s\");\n",
    "print(eighties_counts['today'])\n",
    "print(eighties_counts['yesterday'])\n",
    "print(eighties_counts['internets'])\n",
    "# print(eighties_counts)\n",
    "! nosetests tests/test_classifier.py:test_d3_1_corpus_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ea185220702888d7a8c71aabd3d2bb1",
     "grade": true,
     "grade_id": "cell-d16e0e27d784a477",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deliverable 3.2**: Implement ```estimate_pxy``` in ```naive_bayes.py```. (15 points)\n",
    "- **Test**: `tests/test_classifier.py:test_d3_2_pxy`\n",
    "\n",
    "This function should compute the *smoothed* multinomial distribution $\\log P(x \\mid y)$ for a given label $y$.\n",
    "Note that this function takes the vocabulary as an argument. You have to assign a probability even for words that do not appear in documents with label $y$, if they are in the vocabulary.\n",
    "\n",
    "Hint: You can use ```get_corpus_counts``` in this function if you want to, but you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((vocab))\n",
    "reload(naive_bayes);\n",
    "log_pxy = naive_bayes.estimate_pxy(x_tr_pruned,y_tr,\"1980s\",0.1,vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilities must sum to one! (or very close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999506"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.exp(list(log_pxy.values())))\n",
    "# print(log_pxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the log-probabilities of the words from the hand-tuned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'money': -7.689562807416732, 'name': -7.568324713816848, 'tonight': -6.216637557007502, 'man': -6.63187694645784, 'fly': -8.636944126360918, '**OFFSET**': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print({word:log_pxy[word] for (_,word),weight in theta_hand.items() if weight>0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pxy_more_smooth = naive_bayes.estimate_pxy(x_tr_pruned,y_tr,\"1980s\",1000,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'money': -8.443741629859995, 'name': -8.43282250408468, 'tonight': -8.191919045665923, 'man': -8.295226983039361, 'fly': -8.497300695217104, '**OFFSET**': 0.0}\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 75.059s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "print({word:log_pxy_more_smooth[word] for (_,word),weight in theta_hand.items() if weight>0})\n",
    "! nosetests tests/test_classifier.py:test_d3_2_pxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02ba0ddc081d69799744db19302423f4",
     "grade": true,
     "grade_id": "cell-6bd6e3ed97f4d27a",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deliverable 3.3**: Now you are ready to implement ```estimate_nb``` in ```naive_bayes.py```. (15 points)\n",
    "- **Test**: `tests/test_classifier.py:test_d3_3a_nb`\n",
    "\n",
    "\n",
    "\n",
    "- The goal is that the score given by ```clf_base.predict``` is equal to the joint probability $P(x,y)$, as described in the notes. Therefore, make sure your return output can be feed into ```clf_base.predict```. \n",
    "- Don't forget the offset feature, whose weights should be set to the prior $\\log P(y)$.\n",
    "- The log-probabilities for the offset feature should not be smoothed.\n",
    "- You can call the functions you have defined above, but you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(naive_bayes);\n",
    "theta_nb = naive_bayes.estimate_nb(x_tr_pruned,y_tr,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19504\n"
     ]
    }
   ],
   "source": [
    "print(len(theta_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict for a single instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2000s',\n",
       " {'1980s': -2153.019927798136,\n",
       "  'pre-1980': -2136.8348423968023,\n",
       "  '2000s': -2099.247401056139,\n",
       "  '1990s': -2125.1966084804503})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_base.predict(x_tr_pruned[155],theta_nb,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict for all instances of the development set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46444444444444444\n"
     ]
    }
   ],
   "source": [
    "y_hat = clf_base.predict_all(x_dv_pruned,theta_nb,labels)\n",
    "print(evaluation.acc(y_hat,y_dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46444444444444444"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this block shows how we write and read predictions for evaluation\n",
    "evaluation.write_predictions(y_hat,'nb-dev.preds')\n",
    "y_hat_dv = evaluation.read_predictions('nb-dev.preds')\n",
    "evaluation.acc(y_hat_dv,y_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 91.685s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "# execute this block to write predictions for the test set\n",
    "y_hat = clf_base.predict_all(x_te_pruned,theta_nb,labels)\n",
    "evaluation.write_predictions(y_hat,'nb-test.preds')\n",
    "! nosetests tests/test_classifier.py:test_d3_3a_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f694831543f5f1dc40685eb9c72ff10",
     "grade": true,
     "grade_id": "cell-4fdc212a2f33d245",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deliverable 3.4**: Write a function in ```naive_bayes.py``` called ```find_best_smoother```, which finds the smoothing value that gives best performance on the dev data.  (5 points)\n",
    "- **Test**: `tests/test_classifier.py:test_d3_4a_nb_best`\n",
    "\n",
    "Your function should be trying at least the following values in `vals` below.\n",
    "\n",
    "Then, using this smoothing value, run your Naive Bayes classifier on the test set, and output the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-03 3.16227766e-03 1.00000000e-02 3.16227766e-02\n",
      " 1.00000000e-01 3.16227766e-01 1.00000000e+00 3.16227766e+00\n",
      " 1.00000000e+01 3.16227766e+01 1.00000000e+02]\n"
     ]
    }
   ],
   "source": [
    "vals = np.logspace(-3,2,11)\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(naive_bayes);\n",
    "best_smoother, scores = naive_bayes.find_best_smoother(x_tr_pruned,y_tr,x_dv_pruned,y_dv,vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.001: 0.44666666666666666, 0.0031622776601683794: 0.45111111111111113, 0.01: 0.4577777777777778, 0.03162277660168379: 0.45555555555555555, 0.1: 0.46444444444444444, 0.31622776601683794: 0.4622222222222222, 1.0: 0.45111111111111113, 3.1622776601683795: 0.4688888888888889, 10.0: 0.4666666666666667, 31.622776601683793: 0.32666666666666666, 100.0: 0.28888888888888886}\n",
      "0.28888888888888886\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(best_smoother)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(list(scores.keys()),list(scores.values()),'o-');\n",
    "plt.xlabel('smoothing')\n",
    "plt.ylabel('dev set accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflect:**\n",
    "\n",
    "- what might explain the dramatic drop in accuracy when the smoothing is increased from $10$ to $30$?\n",
    "- before you check, predict whether the accuracy will continue to significantly drop if you further increase the smoothing to $10000$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer Here**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the best parameters for later comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_nb = naive_bayes.estimate_nb(x_tr_pruned,y_tr,best_smoother)\n",
    "y_hat = clf_base.predict_all(x_te_pruned,theta_nb,labels)\n",
    "evaluation.write_predictions(y_hat,'nb-best-test.preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 122.151s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_classifier.py:test_d3_4a_nb_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a526a9b10b356cf7ca27e112b9c18de9",
     "grade": true,
     "grade_id": "cell-f08aaedd2eab9667",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Logistic regression\n",
    "\n",
    "You will implement logistic regression in scikit-learn.\n",
    "\n",
    "**Total: 15 points**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Converting data to numpy\n",
    "\n",
    "Numpy is a package for numerical computing in python.\n",
    "\n",
    "You will need to convert your bag-of-words list of counters to a numpy array. \n",
    "\n",
    "- **Deliverable 4.1**: Implement `preproc.py:make_numpy()` (5 points)\n",
    "- **Test**: `test_pytorch/test_d5_1_numpy`\n",
    "- **Hint**: one approach is to start with `numpy.zeros((height,width))`, and then fill in the cells by iterating through the bag-of-words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((4,2))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0. ]\n",
      " [ 0.  -1. ]\n",
      " [ 1.5  0. ]\n",
      " [ 0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "X[1,1] = -1\n",
    "X[2,0] = 1.5\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(preproc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(preproc);\n",
    "X_tr = preproc.make_numpy(x_tr_pruned,vocab)\n",
    "X_dv = preproc.make_numpy(x_dv_pruned,vocab)\n",
    "X_te = preproc.make_numpy(x_te_pruned,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n",
      "4875\n",
      "(450, 4875)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(len(x_te_pruned))\n",
    "print(len(vocab))\n",
    "print(np.shape(X_te))\n",
    "print(X_te[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1980s', '1990s', '2000s', 'pre-1980']\n"
     ]
    }
   ],
   "source": [
    "label_set = sorted(list(set(y_tr)))\n",
    "print(label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tr = np.array([label_set.index(y_i) for y_i in y_tr])\n",
    "Y_dv = np.array([label_set.index(y_i) for y_i in y_dv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(Y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 84.409s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "! nosetests  tests/test_pytorch.py:test_d5_1_numpy\n",
    "# tests/test_classifier.py:test_d3_4a_nb_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d622cf11a4577e71f2cd9adca2aab57c",
     "grade": true,
     "grade_id": "cell-49ab754e7bf5d388",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Building a logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the model you want to use and make an instance of the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "scikit_log_reg = LogisticRegression(solver='liblinear',max_iter=1000,multi_class='auto')#shows warning messages without these specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr=scikit_log_reg.fit(X_tr, Y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get accuracy of training data and dev data. \n",
    "\n",
    "accuracy is defined as:\n",
    "\n",
    "(fraction of correct predictions): correct predictions / total number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n",
      "0.47333333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_acc = logisticRegr.score(X_tr, Y_tr)\n",
    "dev_acc = logisticRegr.score(X_dv, Y_dv)\n",
    "\n",
    "print(train_acc)\n",
    "print(dev_acc)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 4.2**\n",
    "The noisy progress of the loss and dev set accuracy suggests that something is wrong with our training hyperparameters. Tune the ```LogisticRegression``` parameters until you can get to a dev set accuracy of at least 0.5. You may find a set of tunable parameters here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html \n",
    "(10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5558cc5efbe758b859daca2c8a035f9c",
     "grade": false,
     "grade_id": "cell-25a9f150b5b91c78",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreasing the value of regularization parameters helps to increase the dev set accuracy  since regularization decreases overfitting and increases accuracy on the test set\n"
     ]
    }
   ],
   "source": [
    "def better_model():\n",
    "    x=np.linspace(0.0001,0.8,30)\n",
    "    dev_acc=np.zeros(len(x))\n",
    "    for i,c in enumerate(x):\n",
    "        scikit_log_reg.C=c\n",
    "        logisticRegr=scikit_log_reg.fit(X_tr, Y_tr)\n",
    "        dev_acc[i] = logisticRegr.score(X_dv, Y_dv)\n",
    "    opti=x[np.argmax(dev_acc)]\n",
    "    scikit_log_reg.C=opti\n",
    "    return scikit_log_reg\n",
    "print(\"Decreasing the value of regularization parameters helps to increase the dev set accuracy  since regularization decreases overfitting and increases accuracy on the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90725\n",
      "0.5266666666666666\n"
     ]
    }
   ],
   "source": [
    "scikit_log_reg = better_model()\n",
    "logisticRegr=scikit_log_reg.fit(X_tr, Y_tr)\n",
    "train_acc = logisticRegr.score(X_tr, Y_tr)\n",
    "dev_acc = logisticRegr.score(X_dv, Y_dv)\n",
    "print(train_acc)\n",
    "print(dev_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d6855e35a2ca09953af229fed51aa56",
     "grade": true,
     "grade_id": "cell-8bcf632e35d22f33",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_te = logisticRegr.predict(X_te)\n",
    "np.save('logreg-es-test.preds.npy', np.array(Y_hat_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature analysis\n",
    "\n",
    "**Total: 20 points**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Top Features for Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 5.1**: Implement ```get_top_features_LR``` to output the k most indicative features (**highest features weights**) and the k least indicative features (**lowest features weights**) for each label. (10 points)\n",
    "\n",
    "**Hint**: ```scikit_log_reg.coef_``` is the coefficient of the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the vanilla LR model for comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "scikit_log_reg = LogisticRegression(solver='liblinear',max_iter=1000,multi_class='auto')#shows warning messages without these specifications\n",
    "logisticRegr=scikit_log_reg.fit(X_tr, Y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56eff01050bb662ebda5943d924797ac",
     "grade": false,
     "grade_id": "cell-5bc46cc8e7102922",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['ticket', 'moments', 'tall', 'gentle', 'lord', 'layin', 'mornin', 'grows', 'hardly', 'hoped'], ['NA', 'front', 'needed', 'truth', 'wishing', 'hit', 'sick', 'kids', 'perfect', 'yo'])\n",
      "(['finer', 'againi', 'emotional', 'madness', 'answers', 'lawyers', 'beneath', 'thinks', 'shout', 'america'], ['melt', 'lord', 'begun', 'begin', 'mood', 'opened', 'heavens', 'miles', 'snow', 'tree'])\n",
      "(['scream', 'invisible', 'yeaall', 'mase', 'hit', 'unless', 'thang', 'outside', 'jealousy', 'NA'], ['second', 'miscellaneous', 'broke', 'guitar', 'clean', 'realized', 'meaning', 'pick', 'onto', 'changing'])\n",
      "(['animals', 'shorty', 'independent', 'separate', 'windmill', 'itbaby', 'locked', 'editor', 'shut', 'three'], ['fool', 'playing', 'pimp', 'survive', 'beneath', 'comin', 'rhythm', 'foolish', 'although', 'wall'])\n"
     ]
    }
   ],
   "source": [
    "def get_top_features_LR(scikit_log_reg, vocab,label_set,label,k):\n",
    "    most_indicative_features = []\n",
    "    least_indicative_features = []\n",
    "    lls={}\n",
    "    for i,x in enumerate(label_set):\n",
    "        lls[x]=i\n",
    "    vocab=sorted(vocab) #since a sorted vocab was used while creating the LR numpy theta matrix\n",
    "                      \n",
    "    \n",
    "    coefs=scikit_log_reg.coef_ #each coefficient corresponds to the corresponding element in the vocab list\n",
    "    \n",
    "    Z = [x for _,x in sorted(zip(coefs[lls[label]],vocab))]\n",
    "#     print(vocab,coefs[lls[label]])\n",
    "    most_indicative_features=Z[-k:]\n",
    "    least_indicative_features=Z[:k]\n",
    "    return most_indicative_features, least_indicative_features\n",
    "    \n",
    "print(get_top_features_LR(scikit_log_reg, vocab,label_set,'pre-1980',k=10))\n",
    "print(get_top_features_LR(scikit_log_reg, vocab,label_set,'1980s',k=10))\n",
    "print(get_top_features_LR(scikit_log_reg, vocab,label_set,'1990s',k=10))\n",
    "print(get_top_features_LR(scikit_log_reg, vocab,label_set,'2000s',k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3319d75c241df9fff0f912399bfc947c",
     "grade": true,
     "grade_id": "cell-799477ed44ad2c3a",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Top Features for Naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 5.2**: Implement ```get_top_features_NB``` to output the k most indicative features (**highest features weights**) and the k least indicative features (**lowest features weights**) for each label. (10 points)\n",
    "\n",
    "**Hint**: ```scikit_log_reg.coef_``` is the coefficient of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7d27ad31ca8098b43395c0238ec0b32",
     "grade": false,
     "grade_id": "cell-ad0c24ab6a2c8397",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['love', 'it', 'my', 'me', 'a', 'and', 'to', 'i', 'the', 'you'], ['producer', 'ayer', 'ayayer', 'cd', 'shawty', 'dj', 'wop', 'morn', 'crunk', 'tha'])\n",
      "(['love', 'my', 'it', 'and', 'a', 'me', 'to', 'i', 'the', 'you'], ['sally', 'shoutin', 'yellin', 'starry', 'ba', 'reflection', 'youall', 'ayer', 'ayayer', 'cd'])\n",
      "(['your', 'my', 'it', 'a', 'and', 'me', 'to', 'the', 'i', 'you'], ['sue', 'shoutin', 'starry', 'drives', 'ayer', 'ayayer', 'shawty', 'morn', 'stuntin', 'fights'])\n",
      "(['in', 'my', 'it', 'a', 'to', 'and', 'me', 'the', 'i', 'you'], ['sally', 'shoutin', 'starry', 'hooray', 'jojo', 'native', 'miggida', 'wayif', 'sleepy', 'lovewhen'])\n"
     ]
    }
   ],
   "source": [
    "def get_top_features_NB(theta_nb, label_set,label,k):\n",
    "    features={}\n",
    "    most_indicative_features = []\n",
    "    least_indicative_features = []\n",
    "    for x,y in theta_nb.keys():\n",
    "        if(x==label):\n",
    "            features[y]=theta_nb[(x,y)]\n",
    "    del features['**OFFSET**']\n",
    "    features={k: v for k, v in sorted(features.items(), key=lambda item: item[1])}\n",
    "#     print(features)\n",
    "    least_indicative_features=list(features.keys())[:k]\n",
    "    most_indicative_features=list(features.keys())[-k:]\n",
    "    return most_indicative_features, least_indicative_features\n",
    "\n",
    "print(get_top_features_NB(theta_nb, label_set,'pre-1980',k=10))\n",
    "print(get_top_features_NB(theta_nb, label_set,'1980s',k=10))\n",
    "print(get_top_features_NB(theta_nb, label_set,'1990s',k=10))\n",
    "print(get_top_features_NB(theta_nb, label_set,'2000s',k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad72acd8d24307f5c816a70ef23213b9",
     "grade": true,
     "grade_id": "cell-cff1a381f358be79",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflect:**\n",
    "\n",
    "- Compare the development dataset accuracy of LR and NB, which model do you think is better? \n",
    "- Given those indicative features of LR and NB, which model do you think is better? \n",
    "- You may read https://medium.com/@sangha_deb/naive-bayes-vs-logistic-regression-a319b07a5d4c for more information on a comparison between discriminative and generative models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer Here**: I think the LR model is better in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Precision, Recall, and F1\n",
    "\n",
    "Besides accuracy, systems in natural language processing are evaluated using precision, recall, and F1. Such measures are essential when evaluating on an unbalanced dataset in terms of classes (labels). \n",
    "\n",
    "**Total: 10 points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of data for which the true values are known. \n",
    "\n",
    "In this section, we show one python packages (Seaborn) for making confusion matrixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "predictions = logisticRegr.predict(X_dv)\n",
    "cm = metrics.confusion_matrix(Y_dv, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "ax = sns.heatmap(cm, annot=True, fmt=\".1f\", linewidths=1, square = True, cmap = 'Blues_r');\n",
    "ax.set_ylim(0 ,4)\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0:.4f}'.format(dev_acc)\n",
    "plt.title(all_sample_title, size = 15);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflect**: What do you observe on the above confusion matrix? If you are the leading manager for this team project, which portion of the data would you ask your team to focus on? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer Here**:  In the above confusion matrix, I observe that the predictions for classes for different X_dv values(rows or data points) and the actual class it belongs to. The left-diagonal part of the matrix is for the classes that are classified correctly, and all other parts are the ones classified incorrectly. I see that data points in class 0  ('pre-1980') has been classified the least accurately. So I would ask my team to focus on class 0 followed by class 1. Class 2 and 3 both have higher accuracy of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, Recall, and F1\n",
    "\n",
    "Write a function below that takes in a predicted labels 'Y_hat' and gold labels 'Y', and returns the precision, recall, and F1 for each label.\n",
    "\n",
    "F1 is the harmonic mean of precision and recall. F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "(10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afc055e493602106a86618e6004ac9e6",
     "grade": false,
     "grade_id": "cell-548aaa99996b87ce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1980s', '1990s', '2000s', 'pre-1980']\n",
      "(0.5041322314049587, 0.18654434250764526, 0.27232142857142855)\n",
      "(0.30927835051546393, 0.0970873786407767, 0.14778325123152708)\n",
      "(0.4, 0.11940298507462686, 0.1839080459770115)\n",
      "(0.6212121212121212, 0.23098591549295774, 0.33675564681724846)\n"
     ]
    }
   ],
   "source": [
    "def get_PRF(Y_hat_dv, Y_dv, label_set, label):\n",
    "    precision = 0.0\n",
    "    recall = 0.0\n",
    "    f1 = 0.0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    lls={}\n",
    "    for i,x in enumerate(label_set):\n",
    "        lls[x]=i\n",
    "    cor=lls[label]\n",
    "    for i in range(len(y_hat)): \n",
    "        if Y_dv[i]==Y_hat_dv[i]==cor:\n",
    "               TP+= 1\n",
    "        if Y_hat_dv[i]==cor and Y_dv[i]!= cor:\n",
    "               FP += 1\n",
    "        if Y_dv[i]==Y_hat_dv[i]!= cor:\n",
    "               TN += 1\n",
    "        if Y_hat_dv[i] !=  cor and Y_dv[i]!=cor:\n",
    "               FN += 1\n",
    " \n",
    "    precision=TP/(TP+FP)\n",
    "    recall=TP/(TP+FN)\n",
    "    f1=(2*precision*recall)/(precision+recall)\n",
    "    return precision, recall, f1\n",
    "print(label_set)\n",
    "print(get_PRF(predictions, Y_dv, label_set, 'pre-1980'))\n",
    "print(get_PRF(predictions, Y_dv, label_set, '1980s'))\n",
    "print(get_PRF(predictions, Y_dv, label_set, '1990s'))\n",
    "print(get_PRF(predictions, Y_dv, label_set, '2000s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4657200d4faa8f54f8fe828697340041",
     "grade": true,
     "grade_id": "cell-cf13c8b0aeec0af2",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
