{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 : Topic Modelling\n",
    "\n",
    "In this lab, we will work with research papers published on different aspects of coronaviruses over the years. Our goal is to use topic modelling to know different areas each research paper talks about and answer some important questions regarding the viruses.\n",
    "\n",
    "1. We will begin by first extracting full body text, abstract and title from each paper and cleaning them.\n",
    "2. We will then use gensim library to create a LDA topic model on the extracted body texts.\n",
    "3. We will then use topic modelling and try to find most relevant papers on aspects like vaccine and respiratory viruses.\n",
    "4. Finally, we will look at coherence score as a measure of tuning the number of topics in LDA topic model\n",
    "\n",
    "## Important Instructions - \n",
    "\n",
    "1. Please make changes only inside the graded function. Do not make changes anywhere else in the notebook.\n",
    "2. Please read the description of every graded function very carefully. Description clearly states what is the expectation of each graded function. \n",
    "3. After almost every graded function, there is a cell which you can run and see if the expected output matches the output you are getting. \n",
    "\n",
    "## Grading Policy -\n",
    "1. You will receive full credit if the code passes all test cases.\n",
    "2. In case of error, partial credit will be awarded based on your code and no. of test cases passed ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from  sklearn.cluster import AgglomerativeClustering,SpectralClustering,KMeans\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import seaborn as sns\n",
    "import scispacy\n",
    "import spacy\n",
    "from gensim.models.ldamodel import LdaModel,CoherenceModel\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "customize_stop_words = set([\n",
    "    'doi', 'preprint', 'copyright', 'org', 'https', 'et', 'al', 'author', 'figure', 'table',\n",
    "    'rights', 'reserved', 'permission', 'use', 'used', 'using', 'biorxiv', 'medrxiv', 'license', 'fig', 'fig.', 'al.', 'Elsevier', 'PMC', 'CZI',\n",
    "    '-PRON-', 'usually','study','also'])\n",
    "stop_words=set(list(customize_stop_words)+list(stop_words))\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the purpose of clean_abstract function is to remove stopwords, punctuation, \n",
    "#special characters as well as extra spaces\n",
    "def clean_abstract(abstract):\n",
    "    '''Clean the text, with the option to remove stopwords'''\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    abstract = abstract.lower()\n",
    "    # Clean the text\n",
    "    abstract = re.sub(r\"<br />\", \" \", abstract)\n",
    "    abstract = re.sub(r\"[^a-z]\", \" \", abstract)\n",
    "    abstract = re.sub(r\"   \", \" \", abstract) # Remove any extra spaces\n",
    "    abstract = re.sub(r\"  \", \" \", abstract)\n",
    "    #remove stopwords\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    tokenized = word_tokenize(abstract)\n",
    "    abstract = [lemmatizer.lemmatize(w) for w in tokenized if not w in stop_words and len(w) > 3]\n",
    "    #abstract = \" \".join(abstract)\n",
    "\n",
    "\n",
    "    \n",
    "    # Return a list of words\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The below code cell prepares the following important objects for analysis :\n",
    "\n",
    "1. cleaned_text - list of lists where each sublist is cleaned full text of a research paper. \n",
    "\n",
    "2. text - list of lists where each sublist is full text of a research paper.\n",
    "\n",
    "3. cleaned_titles - list of lists where each sublist is cleaned title of a research paper. \n",
    "\n",
    "4. titles - list of lists where each sublist is title of a research paper. \n",
    "\n",
    "5. abstracts - list of lists where each sublist is abstract of a research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting full text, abstracts and titles and corresponding paper ids from json data.\n",
    "# we will clean the full text and titles.\n",
    "cleaned_text=[]\n",
    "cleaned_titles=[]\n",
    "paper_ids=[]\n",
    "text=[]\n",
    "abstracts=[]\n",
    "titles=[]\n",
    "count=0\n",
    "for file in os.listdir(\"pdf_json\") :\n",
    "    with open('pdf_json/' + file) as json_data:\n",
    "        data=json.load(json_data)\n",
    "        l=data['body_text']\n",
    "        l1=data['abstract']\n",
    "        if len(l1)==0 or len(l)==0:\n",
    "            continue\n",
    "        count+=1\n",
    "        abstract=\"\"\n",
    "        paper_ids.append(data['paper_id'])\n",
    "        for d in l :\n",
    "            abstract+=d[\"text\"]+\" \"\n",
    "        if 'coronavirus' in abstract :\n",
    "            text.append(abstract)\n",
    "            abstract=clean_abstract(abstract)\n",
    "            cleaned_text.append(abstract)\n",
    "            abstract=\"\"\n",
    "            for d in l1 :\n",
    "                abstract+=d[\"text\"]+\" \"\n",
    "            abstracts.append(abstract)\n",
    "            titles.append(data['metadata']['title'])\n",
    "            cleaned_titles.append(clean_abstract(data['metadata']['title']))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 1 (10 marks) :\n",
    "\n",
    "Purpose - To create dictionary and corpus objects which will be used for creating gensim topic model.\n",
    "\n",
    "You should use the corpora package of the gensim library.\n",
    "\n",
    "The input to the function is the cleaned_text list which we have created above.\n",
    "\n",
    "You should return both the dictionary and corpus.\n",
    "\n",
    "For more information on how to create dictionary and corpus, refer the documentation - \n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "def create_corpus(text) :\n",
    "    # start code here\n",
    "    dictio = Dictionary(text)\n",
    "    corpus = [dictio.doc2bow(texts) for texts in text]\n",
    "    # end code here\n",
    "    return dictio, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcam\n",
      "ability\n",
      "able\n",
      "absence\n",
      "abundant\n",
      "accelerated\n",
      "accomplished\n",
      "according\n",
      "accordingly\n",
      "accumulate\n",
      "accumulation\n",
      "acetate\n",
      "achieved\n",
      "acid\n",
      "acknowledged\n",
      "acquire\n",
      "across\n",
      "actin\n",
      "acting\n",
      "active\n"
     ]
    }
   ],
   "source": [
    "dictionary,corpus=create_corpus(cleaned_text)\n",
    "for i in range(20) :\n",
    "    print(dictionary[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output -\n",
    "\n",
    "ability\n",
    "\n",
    "able\n",
    "\n",
    "absence\n",
    "\n",
    "absorbance\n",
    "\n",
    "accca\n",
    "\n",
    "according\n",
    "\n",
    "acid\n",
    "\n",
    "act\n",
    "\n",
    "activated\n",
    "\n",
    "activity\n",
    "\n",
    "acute\n",
    "\n",
    "added\n",
    "\n",
    "addition\n",
    "\n",
    "additional\n",
    "\n",
    "additionally\n",
    "\n",
    "adenoviral\n",
    "\n",
    "adjuvant\n",
    "\n",
    "administered\n",
    "\n",
    "adsorption\n",
    "\n",
    "affect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 2 : (5 marks)\n",
    "\n",
    "Purpose - To create lda topic model using gensim.\n",
    "\n",
    "Inputs will be dictionary and corpus object created above and the no. of top important words from each topic we want to extract.\n",
    "\n",
    "While creating the model, you can keep no. of topics to 8 and random_state=25. You can change these parameters if you want for answering questions but I recevied good results using these parameters. \n",
    "\n",
    "You should return the created lda model and the important words for each topic. \n",
    "\n",
    "There is a method of lda model object which you can use to get top words of each topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lda_model(dictionary,corpus,n_words) :\n",
    "    # start code here\n",
    "    lda = LdaModel(corpus, num_topics=8,random_state=25,id2word=dictionary)\n",
    "    # end code here\n",
    "    return lda,lda.show_topics(num_topics=8, num_words=n_words, formatted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(0, '0.007*\"virus\" + 0.007*\"infection\" + 0.006*\"cell\" + 0.005*\"cat\" + 0.005*\"group\" + 0.005*\"disease\" + 0.005*\"sample\" + 0.004*\"gene\" + 0.004*\"animal\" + 0.003*\"assay\" + 0.003*\"control\" + 0.003*\"however\" + 0.003*\"case\" + 0.003*\"health\" + 0.003*\"number\" + 0.003*\"study\" + 0.003*\"viral\" + 0.003*\"data\" + 0.003*\"time\" + 0.003*\"positive\" + 0.003*\"sequence\" + 0.002*\"analysis\" + 0.002*\"clinical\" + 0.002*\"risk\" + 0.002*\"high\" + 0.002*\"infected\" + 0.002*\"specie\" + 0.002*\"country\" + 0.002*\"type\" + 0.002*\"model\" + 0.002*\"level\" + 0.002*\"different\" + 0.002*\"three\" + 0.002*\"reported\" + 0.002*\"result\" + 0.002*\"pig\" + 0.002*\"detection\" + 0.002*\"shown\" + 0.002*\"treatment\" + 0.002*\"human\"')\n"
     ]
    }
   ],
   "source": [
    "lda_model,topics=create_lda_model(dictionary,corpus,40)\n",
    "print(len(topics))\n",
    "print(topics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, '0.018*\"cell\" + 0.015*\"protein\" + 0.010*\"virus\" + 0.006*\"infection\" + 0.006*\"viral\" + 0.005*\"human\" + 0.004*\"gene\" + 0.004*\"sequence\" + 0.004*\"binding\" + 0.004*\"host\" + 0.004*\"sars\" + 0.003*\"interaction\" + 0.003*\"activity\" + 0.003*\"shown\" + 0.003*\"structure\" + 0.003*\"site\" + 0.003*\"different\" + 0.003*\"data\" + 0.003*\"genome\" + 0.003*\"mouse\" + 0.003*\"analysis\" + 0.002*\"response\" + 0.002*\"type\" + 0.002*\"factor\" + 0.002*\"result\" + 0.002*\"infected\" + 0.002*\"however\" + 0.002*\"could\" + 0.002*\"replication\" + 0.002*\"target\" + 0.002*\"found\" + 0.002*\"receptor\" + 0.002*\"acid\" + 0.002*\"fusion\" + 0.002*\"sample\" + 0.002*\"domain\" + 0.002*\"high\" + 0.002*\"animal\" + 0.002*\"effect\" + 0.002*\"function\"')\n",
      "(2, '0.014*\"cell\" + 0.011*\"protein\" + 0.007*\"viral\" + 0.006*\"infection\" + 0.006*\"virus\" + 0.006*\"sequence\" + 0.005*\"mers\" + 0.005*\"human\" + 0.005*\"antibody\" + 0.004*\"sample\" + 0.004*\"response\" + 0.004*\"anti\" + 0.003*\"gene\" + 0.003*\"patient\" + 0.003*\"infected\" + 0.003*\"sars\" + 0.003*\"result\" + 0.003*\"analysis\" + 0.003*\"activity\" + 0.003*\"time\" + 0.003*\"well\" + 0.003*\"receptor\" + 0.003*\"effect\" + 0.003*\"type\" + 0.003*\"group\" + 0.003*\"animal\" + 0.003*\"high\" + 0.003*\"based\" + 0.003*\"peptide\" + 0.002*\"treatment\" + 0.002*\"specific\" + 0.002*\"genome\" + 0.002*\"respiratory\" + 0.002*\"mouse\" + 0.002*\"disease\" + 0.002*\"observed\" + 0.002*\"strain\" + 0.002*\"data\" + 0.002*\"study\" + 0.002*\"control\"')\n",
      "(3, '0.014*\"virus\" + 0.010*\"cell\" + 0.008*\"infection\" + 0.008*\"viral\" + 0.008*\"protein\" + 0.005*\"sequence\" + 0.005*\"human\" + 0.004*\"host\" + 0.004*\"disease\" + 0.004*\"different\" + 0.004*\"specie\" + 0.003*\"analysis\" + 0.003*\"replication\" + 0.003*\"study\" + 0.003*\"model\" + 0.003*\"data\" + 0.003*\"however\" + 0.003*\"membrane\" + 0.003*\"gene\" + 0.003*\"result\" + 0.003*\"sample\" + 0.003*\"expression\" + 0.003*\"infected\" + 0.003*\"transmission\" + 0.002*\"strain\" + 0.002*\"level\" + 0.002*\"based\" + 0.002*\"specific\" + 0.002*\"type\" + 0.002*\"individual\" + 0.002*\"time\" + 0.002*\"genome\" + 0.002*\"response\" + 0.002*\"found\" + 0.002*\"number\" + 0.002*\"effect\" + 0.002*\"case\" + 0.002*\"well\" + 0.002*\"shown\" + 0.002*\"bat\"')\n",
      "(4, '0.021*\"cell\" + 0.010*\"protein\" + 0.010*\"virus\" + 0.009*\"infection\" + 0.007*\"viral\" + 0.006*\"infected\" + 0.005*\"pedv\" + 0.005*\"strain\" + 0.004*\"gene\" + 0.003*\"antibody\" + 0.003*\"replication\" + 0.003*\"analysis\" + 0.003*\"result\" + 0.003*\"type\" + 0.003*\"sample\" + 0.003*\"response\" + 0.003*\"human\" + 0.003*\"shown\" + 0.003*\"tgev\" + 0.003*\"genome\" + 0.003*\"sequence\" + 0.003*\"observed\" + 0.003*\"expression\" + 0.003*\"assay\" + 0.003*\"level\" + 0.003*\"mers\" + 0.003*\"time\" + 0.003*\"binding\" + 0.003*\"control\" + 0.003*\"vaccine\" + 0.003*\"group\" + 0.002*\"specific\" + 0.002*\"three\" + 0.002*\"anti\" + 0.002*\"data\" + 0.002*\"could\" + 0.002*\"domain\" + 0.002*\"host\" + 0.002*\"however\" + 0.002*\"site\"')\n",
      "(5, '0.022*\"cell\" + 0.014*\"virus\" + 0.010*\"protein\" + 0.009*\"infection\" + 0.007*\"viral\" + 0.007*\"mouse\" + 0.007*\"expression\" + 0.007*\"gene\" + 0.005*\"infected\" + 0.004*\"level\" + 0.004*\"response\" + 0.004*\"activity\" + 0.003*\"human\" + 0.003*\"result\" + 0.003*\"host\" + 0.003*\"effect\" + 0.003*\"well\" + 0.003*\"strain\" + 0.003*\"data\" + 0.003*\"control\" + 0.003*\"group\" + 0.003*\"immune\" + 0.003*\"ifitm\" + 0.003*\"time\" + 0.003*\"analysis\" + 0.003*\"type\" + 0.003*\"replication\" + 0.003*\"antiviral\" + 0.003*\"anti\" + 0.002*\"disease\" + 0.002*\"antibody\" + 0.002*\"shown\" + 0.002*\"sequence\" + 0.002*\"however\" + 0.002*\"sample\" + 0.002*\"mrna\" + 0.002*\"different\" + 0.002*\"specific\" + 0.002*\"observed\" + 0.002*\"compared\"')\n",
      "(6, '0.022*\"virus\" + 0.011*\"cell\" + 0.009*\"protein\" + 0.009*\"viral\" + 0.007*\"infection\" + 0.007*\"sequence\" + 0.006*\"sample\" + 0.004*\"genome\" + 0.004*\"antibody\" + 0.003*\"data\" + 0.003*\"analysis\" + 0.003*\"gene\" + 0.003*\"sars\" + 0.003*\"number\" + 0.003*\"result\" + 0.003*\"time\" + 0.003*\"infected\" + 0.003*\"respiratory\" + 0.003*\"assay\" + 0.003*\"human\" + 0.003*\"positive\" + 0.002*\"different\" + 0.002*\"influenza\" + 0.002*\"however\" + 0.002*\"acid\" + 0.002*\"well\" + 0.002*\"patient\" + 0.002*\"level\" + 0.002*\"could\" + 0.002*\"host\" + 0.002*\"high\" + 0.002*\"strain\" + 0.002*\"site\" + 0.002*\"vaccine\" + 0.002*\"detected\" + 0.002*\"shown\" + 0.002*\"control\" + 0.002*\"specific\" + 0.002*\"group\" + 0.002*\"binding\"')\n",
      "(7, '0.012*\"patient\" + 0.011*\"infection\" + 0.009*\"virus\" + 0.007*\"case\" + 0.007*\"respiratory\" + 0.005*\"disease\" + 0.005*\"viral\" + 0.005*\"influenza\" + 0.005*\"sample\" + 0.004*\"child\" + 0.004*\"data\" + 0.004*\"clinical\" + 0.004*\"group\" + 0.004*\"result\" + 0.003*\"study\" + 0.003*\"year\" + 0.003*\"human\" + 0.003*\"mers\" + 0.003*\"analysis\" + 0.003*\"time\" + 0.003*\"cell\" + 0.003*\"pathogen\" + 0.003*\"control\" + 0.003*\"number\" + 0.003*\"sars\" + 0.003*\"positive\" + 0.003*\"test\" + 0.003*\"associated\" + 0.003*\"reported\" + 0.003*\"among\" + 0.003*\"detected\" + 0.003*\"outbreak\" + 0.003*\"level\" + 0.003*\"found\" + 0.003*\"hospital\" + 0.003*\"pneumonia\" + 0.003*\"however\" + 0.002*\"rate\" + 0.002*\"symptom\" + 0.002*\"detection\"')\n"
     ]
    }
   ],
   "source": [
    "#Printing the list of topics to see which one has the highest proportion of certains words\n",
    "for x in range(1,8):\n",
    "    print(topics[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output -\n",
    "\n",
    "len(topics) = 8\n",
    "\n",
    "topics[0] =\n",
    "\n",
    "(0,\n",
    " '0.014*\"virus\" + 0.007*\"sample\" + 0.007*\"sequence\" + 0.006*\"cell\" + 0.006*\"sars\" + 0.006*\"viral\" + 0.006*\"infection\" + 0.005*\"human\" + 0.004*\"disease\" + 0.004*\"time\" + 0.004*\"result\" + 0.003*\"patient\" + 0.003*\"data\" + 0.003*\"case\" + 0.003*\"genome\" + 0.003*\"protein\" + 0.003*\"positive\" + 0.003*\"clinical\" + 0.003*\"primer\" + 0.003*\"study\"')\n",
    " \n",
    "#### Note - This output will change if no. of topics and random_state are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 3 : (15 marks)\n",
    "\n",
    "Purpose - To get the top 20 papers for a given topic number.  A given paper belongs to the topic no. whose proportion is the highest among all topics in the paper. To get the composition of all topics in a paper, use the get_document_topics() function of the lda model object. \n",
    "\n",
    "Input is the topic no.(0 based indexing)\n",
    "\n",
    "After getting all the papers belonging to the topic no. k(input), sort them based on the proportion of topic k they have in descending order and return 20 papers with highest amount of topic k in them.\n",
    "\n",
    "Output will be a list of tuples with paper no. as 1st value and proportion of topic k as 2nd value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_articles(k) :\n",
    "    # start code here\n",
    "    doc_topics=lda_model.get_document_topics(corpus)\n",
    "    track_dict=[]\n",
    "    for x,y in enumerate(doc_topics):\n",
    "        for tup in y:\n",
    "            if (tup[0]==k):\n",
    "                track_dict.append((x,tup[1]))\n",
    "    sort_flat=sorted(track_dict, key = lambda x: x[1],reverse=True)\n",
    "    return sort_flat[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2595, 0.99980026),\n",
       " (2409, 0.9997993),\n",
       " (2086, 0.9997805),\n",
       " (2785, 0.99975777),\n",
       " (1382, 0.99968994),\n",
       " (2331, 0.9996309),\n",
       " (3608, 0.9995981),\n",
       " (3659, 0.9995814),\n",
       " (1805, 0.99954945),\n",
       " (2431, 0.9995453),\n",
       " (271, 0.9995075),\n",
       " (1106, 0.9995037),\n",
       " (2699, 0.99944925),\n",
       " (2406, 0.9994471),\n",
       " (2468, 0.99942887),\n",
       " (1879, 0.99942493),\n",
       " (2117, 0.9994037),\n",
       " (2857, 0.99937415),\n",
       " (2271, 0.9993598),\n",
       " (212, 0.99933577)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_0=get_top_articles(0)\n",
    "top_20_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Value -\n",
    "\n",
    "[(2215, 0.9996958),\n",
    "\n",
    " (1954, 0.9996701),\n",
    " \n",
    " (3684, 0.9996221),\n",
    " \n",
    " (1342, 0.99961907),\n",
    " \n",
    " (3524, 0.9995674),\n",
    " \n",
    " (3492, 0.999553),\n",
    " \n",
    " (2277, 0.99951327),\n",
    " \n",
    " (519, 0.9992938),\n",
    " \n",
    " (2817, 0.99925375),\n",
    " \n",
    " (2256, 0.99917614),\n",
    " \n",
    " (965, 0.9991082),\n",
    " \n",
    " (3732, 0.9990591),\n",
    " \n",
    " (1369, 0.9988257),\n",
    " \n",
    " (1225, 0.9977632),\n",
    " \n",
    " (3263, 0.99463576),\n",
    " \n",
    " (3532, 0.9943344),\n",
    " \n",
    " (716, 0.9935407),\n",
    " \n",
    " (2372, 0.99306047),\n",
    " \n",
    " (3267, 0.9916947),\n",
    " \n",
    " (897, 0.9912204)]\n",
    " \n",
    "#### Note - This output will change if no. of topics and random_state are different in LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 :  What do we know about vaccine development efforts for viruses? (5 marks) \n",
    "\n",
    "You should look to get the most relevant 20 articles on the subject of vaccines for varius viruses.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccine_articles=get_top_articles(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recombinant Chimeric Transmissible Gastroenteritis Virus (TGEV)-Porcine Epidemic Diarrhea Virus (PEDV) Virus Provides Protection against Virulent PEDV\n",
      "\n",
      "\n",
      "Trypsin-independent porcine epidemic diarrhea virus US strain with altered virus entry mechanism\n",
      "\n",
      "\n",
      "The Program for New Century Excellent Talents in University of Ministry of Education of P.R. China (NCET-10-0144), Sponsored by Chang Jiang Scholar Candidates Programme for Provincial Universities in Heilongjiang\n",
      "\n",
      "\n",
      "Contribution of porcine aminopeptidase N to porcine deltacoronavirus infection\n",
      "\n",
      "\n",
      "Genetic manipulation of porcine deltacoronavirus reveals insights into NS6 and NS7 functions: a novel strategy for vaccine design\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,x in vaccine_articles[:5] :\n",
    "    print(titles[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analyzing the output of function 2 we see that among the 8 topics listed the probability of word vaccine occurring in them for the top 40 words is low. However,   topic[4] has the word vaccine with a probablity =0.003*\"vaccine\". So we choose it to get the most relevant 20 articles on the subject of vaccines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output - \n",
    "\n",
    "REVIEW Intranasal and oral vaccination with protein-based antigens: advantages, challenges and formulation strategies\n",
    "\n",
    "\n",
    "Peptide Vaccine: Progress and Challenges\n",
    "\n",
    "\n",
    "Journal of Immune Based Therapies and Vaccines Prospects for control of emerging infectious diseases with plasmid DNA vaccines\n",
    "\n",
    "\n",
    "Emergence of Pathogenic Coronaviruses in Cats by Homologous Recombination between Feline and Canine Coronaviruses\n",
    "\n",
    "\n",
    "Effects of Adjuvants on the Immunogenicity and Efficacy of a Zika Virus Envelope Domain III Subunit Vaccine\n",
    "\n",
    "#### Note - This output may vary based on your parameters of the LDA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 : What do we know about other viruses causing respiratory problems in adults and children? (5 marks)\n",
    "\n",
    "You should look to get the most relevant 20 articles on the subject of respiratory problems in adults and children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_articles=get_top_articles(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respiratory Virus Infections in Hematopoietic Cell Transplant Recipients\n",
      "\n",
      "\n",
      "viruses Perspective Potential Maternal and Infant Outcomes from Coronavirus 2019-nCoV (SARS-CoV-2) Infecting Pregnant Women: Lessons from SARS, MERS, and Other Human Coronavirus Infections\n",
      "\n",
      "\n",
      "Exposure Patterns Driving Ebola Transmission in West Africa: A Retrospective Observational Study International Ebola Response Team\n",
      "\n",
      "\n",
      "Bacterial and viral pathogen spectra of acute respiratory infections in under-5 children in hospital settings in Dhaka city\n",
      "\n",
      "\n",
      "Goal-Oriented Respiratory Management for Critically Ill Patients with Acute Respiratory Distress Syndrome\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,x in resp_articles[:5] :\n",
    "    print(titles[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analyzing the output of function 2, we see that among the 8 topics listed the probability of word \"resipiratory\" and \"child\" occurring in them for the top 40 words is highest in topic[7]. So we choose topic[7] to get the most relevant 20 articles on the subject of respiratory problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output - \n",
    "\n",
    "Comparing Human Metapneumovirus and Respiratory Syncytial Virus: Viral Co- Detections, Genotypes and Risk Factors for Severe Disease\n",
    "\n",
    "\n",
    "Bocavirus Infection in Otherwise Healthy Children with Respiratory Disease\n",
    "\n",
    "\n",
    "Surveillance and Genome Analysis of Human Bocavirus in Patients with Respiratory Infection in Guangzhou\n",
    "\n",
    "\n",
    "Imported Case of Acute Respiratory Tract Infection Associated with a Member of Species Nelson Bay Orthoreovirus\n",
    "\n",
    "\n",
    "Clinical Epidemiology of Bocavirus, Rhinovirus, Two Polyomaviruses and Four Coronaviruses in HIV-Infected and HIV-Uninfected South African Children\n",
    "\n",
    "#### Note - This output may vary based on your parameters of the LDA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 4 : (10 marks)\n",
    "\n",
    "Purpose - To calculate coherence score of LDA model for different no. of topics.\n",
    "\n",
    "Input will be a list of no. of topics for which we want to calculate coherence score.\n",
    "\n",
    "Output will be a list of tuples where the 1st element is no. of topics and 2nd element is coherence score.\n",
    "\n",
    "Please refer the following documentation on coherence score -\n",
    "\n",
    "https://radimrehurek.com/gensim/models/coherencemodel.html\n",
    "\n",
    "Please use coherence='c_v' in CoherenceModel. Also, keep random_state=25 in lda model to get the same expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "def get_coherence_scores(n_topics) :\n",
    "    # start code here\n",
    "    cm_score=[]\n",
    "    for x in n_topics:\n",
    "        model2 = LdaModel(corpus, num_topics=x,random_state=25,id2word=dictionary)\n",
    "        cm = CoherenceModel(model=model2,texts=cleaned_text, corpus=corpus,dictionary=dictionary, coherence='c_v')\n",
    "        cm_score.append((x,cm.get_coherence()))\n",
    "    # end code here\n",
    "    return cm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.3237877027385651),\n",
       " (6, 0.34323254567915923),\n",
       " (8, 0.3383538853673067),\n",
       " (10, 0.3341392450816718)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_topics=[3,6,8,10]\n",
    "coherence_scores=get_coherence_scores(n_topics)\n",
    "coherence_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output -\n",
    "\n",
    "[(3, 0.3271153212140945),\n",
    "\n",
    " (6, 0.3278043307090321),\n",
    " \n",
    " (8, 0.3396271207143783),\n",
    " \n",
    " (10, 0.33361763232155234)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
